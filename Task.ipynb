{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = requests.get('https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population').text\n",
    "soup = BeautifulSoup(website_url,'lxml')\n",
    "My_table = soup.find('table',{'class':'wikitable sortable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = 'https://en.wikipedia.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "for row in My_table.tbody.findAll('tr'):\n",
    "    links = row.find_all('a')[0]\n",
    "    #print(links['href'])\n",
    "    link = wiki+links['href']\n",
    "    link_list.append(link)\n",
    "    #print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows = My_table.find_all('tr')\n",
    "res = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text.strip() for tr in td if tr.text.strip()]\n",
    "    if row:\n",
    "        res.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(res)\n",
    "data.columns = ['2017 rank', 'City', 'State', '2017 estimate', '2010 Census',\n",
    "                                                         'Change', '2016 land area Sq Mi','2016 land area Sq Km',\n",
    "                 '2016 population density/sq Mi', '2016 population/sq Km', 'Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in data.iterrows():\n",
    "    row['City'] = re.sub(r'\\[.*?\\]', '', row['City'])\n",
    "    row['2016 land area Sq Mi'] = re.sub(\"\\D\", \"\", row['2016 land area Sq Mi'])\n",
    "    row['2016 land area Sq Km'] = re.sub(\"\\D\", \"\", row['2016 land area Sq Km'])\n",
    "    row['2016 population density/sq Mi'] = re.sub(\"\\D\", \"\", row['2016 population density/sq Mi'])\n",
    "    row['2016 population/sq Km'] = re.sub(\"\\D\", \"\", row['2016 population/sq Km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Wikipedia Link'] = link_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = []\n",
    "for l in link_list[1:]:\n",
    "    website_url = requests.get(l).text\n",
    "    soup = BeautifulSoup(website_url,'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    k = tables[0].findAll('a')\n",
    "    if(len(k)<20):\n",
    "        k = tables[1].findAll('a')\n",
    "    if(len(k)<20):\n",
    "        k = tables[2].findAll('a')\n",
    "    w = k[len(k) - 1]['href']\n",
    "    if \"wikidata\" in w:\n",
    "        w = k[len(k) - 2]['href']\n",
    "    web.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City Website'] = web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('my_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
